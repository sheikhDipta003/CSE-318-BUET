========================AI===========================
# Goal formulation, based on the current situation and the agent’s performance
measure, is the first step in problem solving.

# The agent’s task is to find out how to act, now and in the future, so that it
reaches a goal state.

# Problem formulation is the process of deciding what actions
and states to consider, given a goal.

# we assume that the environment is observable, so the agent always knows the current state.

# We also assume the environment is discrete,
so at any given state there are only finitely many actions to choose from.

# We will assume the environment is known, so the agent knows which states are reached by each
action.

# we assume that the environment is deterministic, so each action has exactly one
outcome

# The process of looking for a sequence of actions that reaches the goal is called search.

#  leaf node:  a node
with no children in the tree. The set of all leaf nodes available for expansion at any given
point is called the frontier.

# A problem can be defined formally by five components:

- The "initial state" that the agent starts in.

- A description of the possible "actions" available to the agent. Given a particular state s,
ACTIONS(s) returns the set of actions that can be executed in s.

- "transition model", specified by a function RESULT(s, a) that returns the state that results from
doing action a in state s. Together, the initial state, actions, and transition model implicitly define the "state space"
of the problem- the set of all states reachable from the initial state by any sequence of actions. A path through the state 
space from the initial state to a goal state is a solution.

- The "goal test", which determines whether a given state is a goal state.

- A "path cost" function that assigns a numeric cost to each path. The "step cost" of taking action
a in state s to reach state s′ is denoted by c(s, a, s′). 

# The traveling salesperson problem (TSP) is a touring problem in which each city
must be visited exactly once. The aim is to find the shortest tour. The problem is known to
be NP-hard.

# A VLSI layout problem requires positioning millions of components and connections
on a chip to minimize area, minimize circuit delays, minimize stray capacitances, and maximize manufacturing yield.

# We can evaluate an algorithm’s performance in
four ways:
- Completeness: Is the algorithm guaranteed to find a solution when there is one?
- Optimality: Does the strategy find the optimal solution?
- Time complexity: How long does it take to find a solution?
- Space complexity: How much memory is needed to perform the search?

# In AI, the graph is often
represented implicitly by the initial state, actions, and transition model and is frequently infinite. For these reasons, 
complexity is expressed in terms of three quantities: b, the branching
factor or maximum number of successors of any node; d, the depth of the shallowest goal
node (i.e., the number of steps along the path from the root); and m, the maximum length of
any path in the state space. Time is often measured in terms of the number of nodes generated
during the search, and space in terms of the maximum number of nodes stored in memory.

# function TREE-SEARCH(problem, strategy) returns a solution, or failure
	initialize the frontier using the initial state of problem
	loop do
		if the frontier is empty then return failure
		choose a leaf node according to strategy and remove it from the frontier
		if the node contains a goal state then return the corresponding solution
		expand the chosen node, adding the resulting nodes to the frontier

function GRAPH-SEARCH(problem) returns a solution, or failure
	initialize the frontier using the initial state of problem
	initialize the explored set to be empty
	loop do
		if the frontier is empty then return failure
		choose a leaf node and remove it from the frontier
		if the node contains a goal state then return the corresponding solution
		add the node to the explored set
		expand the chosen node, adding the resulting nodes to the frontier
			only if not in the frontier or explored set

# Uninformed Search: All they can do is
generate successors and distinguish a goal state from a non-goal state. All search strategies
are distinguished by the order in which nodes are expanded. Strategies that know whether
one non-goal state is “more promising” than another are called informed search or heuristic
search strategies.

# Breadth-first search is a simple strategy in which the root node is expanded first, then all the
successors of the root node are expanded, then their successors, and so on.

- the shallowest unexpanded node is chosen for expansion. This is achieved very simply
by using a FIFO queue for the frontier

- new nodes (which are always deeper than their
parents) go to the back of the queue, and old nodes, which are shallower than the new nodes,
get expanded first.

- the goal test is applied to each node when it is generated rather than when it is selected for
expansion.

- Figure 3.11 Breadth-first search on a graph

function BREADTH-FIRST-SEARCH(problem) returns a solution, or failure
	node ← a node with STATE = problem.INITIAL-STATE, PATH-COST = 0
	if problem.GOAL-TEST(node.STATE) then return SOLUTION(node)
	frontier ← a FIFO queue with node as the only element
	explored ← an empty set
	loop do
		if EMPTY?( frontier) then return failure
		node ← POP( frontier) /* chooses the shallowest node in frontier */
		add node.STATE to explored
		for each action in problem.ACTIONS(node.STATE) do
			child ← CHILD-NODE(problem, node, action)
			if child.STATE is not in explored or frontier then
				if problem.GOAL-TEST(child.STATE) then return SOLUTION(child)
				frontier ← INSERT(child, frontier)

- Completeness: if the shallowest goal node is at some finite depth
d, BFS will eventually find it after generating all shallower nodes. Note that as soon as a goal node is generated, we know it
is the shallowest goal node because all shallower nodes must have been generated already
and failed the goal test.

- breadth-first search is optimal if the path cost is a nondecreasing function of the
depth of the node. The most common such scenario is that all actions have the same cost.

- Time complexity: the total number of nodes generated is
b + b^2 + b^3 + ··· + b^d = O(b^d).

- Space complexity:  For breadth-first graph search in particular, every node generated remains in
memory. There will be O(b^(d−1)) nodes in the explored set and O(b^d) nodes in the frontier. so the space complexity is O(b^d).

- the memory requirements are a
bigger problem for breadth-first search than is the execution time.

- exponential-time-complexity search problems
cannot be solved by uninformed methods for any but the smallest instances


# Uniform-cost search is an algorithm that is optimal
with any step-cost function. Instead of expanding the shallowest node, uniform-cost search
expands the node n with the lowest path cost g(n).

- Figure 3.14 Uniform-cost search on a graph.

function UNIFORM-COST-SEARCH(problem) returns a solution, or failure
	node ← a node with STATE = problem.INITIAL-STATE, PATH-COST = 0
	frontier ← a priority queue ordered by PATH-COST, with node as the only element
	explored ← an empty set
	loop do
		if EMPTY?( frontier) then return failure
		node ← POP( frontier) /* chooses the lowest-cost node in frontier */
		if problem.GOAL-TEST(node.STATE) then return SOLUTION(node)
		add node.STATE to explored
		for each action in problem.ACTIONS(node.STATE) do
			child ← CHILD-NODE(problem, node, action)
			if child.STATE is not in explored or frontier then
				frontier ← INSERT(child, frontier)
			else if child.STATE is in frontier with higher PATH-COST then
				replace that frontier node with child

- the goal test is applied to a node when
it is selected for expansion rather than when it is first generated since the first generated node maybe on a suboptimal path.

- a test is added in case a better
path is found to a node currently on the frontier.

- Optimality: 
First, we observe that
whenever uniform-cost search selects a node n for expansion, the optimal path to that node
has been found (Were this not the case, there would have to be another frontier node n′ on
the optimal path from root to n, which would have lower g-cost and so would've been selected first). Then,
because step costs are nonnegative, paths never get shorter as nodes are added. These two
facts together imply that uniform-cost search expands nodes in order of their optimal path
cost.

- Completeness is
guaranteed provided the cost of every step exceeds some small positive constant .

- let C* be the cost of the optimal solution,
and assume that every action costs at least ϵ. Then the algorithm’s worst-case time and space
complexity is O(b^1+[C*/ϵ]), which can be much greater than b^d.



# Depth-first search always expands the deepest node in the current frontier of the search tree.

- depth-first search uses a LIFO queue.
A LIFO queue means that the most recently generated node is chosen for expansion.

- The graph-search version, which avoids repeated states and redundant paths, is complete in finite state spaces because 
it will eventually expand every node.

- nonoptimal. For example, in Figure 3.16, depthfirst search will explore the entire left-subtree of root node A even if node C 
is a goal node. 
If node J (in left-subtree) were also a goal node, then depth-first search would return it as a solution instead of C, which
would be a better solution; hence, depth-first search is not optimal.

- The time complexity of depth-first graph search is bounded by the size of the state space.
A depth-first tree search, on the other hand, may generate
all of the O(b^m) nodes in the search tree, where m is the maximum depth of any node; this
can be much greater than the size of the state space. Note that m itself can be much larger
than d (the depth of the shallowest solution)

- Space complexity: Once a node has been expanded, it can be removed from memory as soon as all its
descendants have been fully explored. For a state space with branching
factor b and maximum depth m, depth-first search requires storage of only O(bm) nodes.


# informed search strategy— one that uses problem-specific knowledge beyond the definition of the problem itself

- The general approach we consider is called best-first search. Here, a node is
selected for expansion based on an evaluation function, f(n). The node with the lowest evaluation is expanded first. The
implementation of best-first graph search is identical to that for uniform-cost search, except for the use of f instead of g to 
order the priority queue.

- The choice of f determines the search strategy. Most best-first algorithms
include as a component of f a heuristic function, denoted h(n):
h(n) = estimated cost of the cheapest path from the state at node n to a goal state.

# Greedy best-first search tries to expand the node that is closest to the goal, on the grounds
that this is likely to lead to a solution quickly. Thus, it evaluates nodes by using just the
heuristic function; that is, f(n) = h(n).

- Complete? 
Not unless it uses GRAPH-SEARCH instead of TREE-SEARCH
Otherwise can get stuck in loops

- greedy best-first search using hSLD finds a solution without ever
expanding a node that is not on the solution path; hence, its search cost is minimal. It is
not optimal, however.

- The
worst-case time and space complexity for the tree version is O(b^m), where m is the maximum
depth of the search space.

# A* search evaluates nodes by combining g(n), the cost to reach the node, and h(n), the cost
to get from the node to the goal:
f(n) = g(n) + h(n) .

Thus, f(n) = estimated cost of the cheapest solution through n .

- The algorithm is identical to UNIFORM-COST-SEARCH except
that A* uses g + h instead of g.

- A* search is
both complete and optimal

- The first condition we require for optimality is that h(n) be an admissible heuristic. An
admissible heuristic is one that never overestimates the cost to reach the goal. 

- A second, slightly stronger condition called consistency (or sometimes monotonicity) is required only for applications of A* to graph search. A heuristic h(n) is consistent if, for
every node n and every successor n′ of n generated by any action a, the estimated cost of
reaching the goal from n is no greater than the step cost of getting to n′ plus the estimated
cost of reaching the goal from n′:
h(n) ≤ c(n, a, n′) + h(n′) .

- A* has the following properties: the tree-search version of A* is
optimal if h(n) is admissible, while the graph-search version is optimal if h(n) is consistent.

# Figure 3.26 The algorithm for recursive best-first search

function RECURSIVE-BEST-FIRST-SEARCH(problem) returns a solution, or failure
	return RBFS(problem, MAKE-NODE(problem.INITIAL-STATE),∞)

function RBFS(problem, node, f_limit) returns a solution, or failure and a new f-cost limit
	if problem.GOAL-TEST(node.STATE) then return SOLUTION(node)
	successors ← [ ]
	for each action in problem.ACTIONS(node.STATE) do
		add CHILD-NODE(problem, node, action) into successors
	if successors is empty then return failure, ∞
	for each s in successors do /* update f with value from previous search, if any */
		s.f ← max(s.g + s.h, node.f ))
	loop do
		best ← the lowest f-value node in successors
		if best.f > f_limit then return failure, best.f
		alternative ← the second-lowest f-value among successors
		result, best.f ← RBFS(problem, best, min( f_limit, alternative))
		if result != failure then return result

- mimic the operation of standard best-first search, but using only linear space

- Similar to DFS, but keeps track of the f-value of the best alternative path available from any ancestor of the current node

- If current node exceeds f-limit -> backtrack to alternative path

- As it backtracks, replace f-value of each node along the path with the best f(n) value of its children.
This allows it to return to this subtree, if it turns out to look better than alternatives.

- Optimal if h(n) is admissible

- Time complexity difficult to characterize
Depends on accuracy if h(n) and how often best path changes.
Can end up “switching” back and forth.

- Space complexity is O(bd)
Other extreme to A* - uses too little memory.


# Local Search

- we look at what happens
when these assumptions: observable, deterministic, known environments where the solution is a sequence of actions,
are relaxed.

- evaluating and modifying one or more current states in the state space rather than systematically exploring paths from an initial state

- These algorithms are suitable for problems in which all that matters is the solution state, not
the path cost to reach it.

- Keep track of single current state

- Move only to neighboring states

- two key advantages: (1) they use very little
memory—usually a constant amount; and (2) they can often find reasonable solutions in large
or infinite (continuous) state spaces for which systematic algorithms are unsuitable

- useful for solving pure optimization problems, in which the aim is to find the best state according to an objective function.

- there is no “goal test” and
no “path cost” for these problems

- A complete local search algorithm always finds a goal if one exists;
an optimal algorithm always finds a global minimum/maximum.


# Hill-climbing search

- 
function HILL-CLIMBING(problem) returns a state that is a local maximum
	current ← MAKE-NODE(problem.INITIAL-STATE)
	loop do
		neighbor ← a highest-valued successor of current
		if neighbor.VALUE ≤ current.VALUE then return current.STATE
		current ← neighbor

- Local search algorithms typically use a complete-state formulation, where each state has
8 queens on the board, one per column

- The hill-climbing algorithms described so far are incomplete—they often fail to find
a goal when one exists because they can get stuck on local maxima